{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a405aa8",
   "metadata": {},
   "source": [
    "# Berlin City-Wide Emissions - Cleaning and Transformation\n",
    "\n",
    "This notebook cleans and transforms the dataset `CSV data/2023_City_Wide_Emissions_Berlin.csv`.\n",
    "Each step includes a markdown explanation and detailed code so you can follow the workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3ca431",
   "metadata": {},
   "source": [
    "## 1. Imports\n",
    "Load the required libraries and configure display options for better readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c862a829",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Core analysis libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Display more columns when inspecting DataFrames\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.width', 140)\n",
    "\n",
    "# Set a consistent plotting theme\n",
    "sns.set_theme(style='whitegrid', palette='deep')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb3d1d18",
   "metadata": {},
   "source": [
    "## 2. Load the dataset\n",
    "Read the CSV into a DataFrame, preview the first rows, and record the initial shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c029344",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to the raw data\n",
    "DATA_PATH = Path('CSV data') / '2023_City_Wide_Emissions_Berlin.csv'\n",
    "\n",
    "# Load the dataset\n",
    "df_raw = pd.read_csv(DATA_PATH)\n",
    "initial_shape = df_raw.shape\n",
    "\n",
    "print(f'Loaded data from: {DATA_PATH}')\n",
    "print(f'Initial shape (rows, columns): {initial_shape}')\n",
    "df_raw.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781ae22e",
   "metadata": {},
   "source": [
    "## 3. Column cleaning\n",
    "Strip stray whitespace, rename verbose headers, and convert names to snake_case for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af313eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Work on a copy so the raw frame is preserved\n",
    "df = df_raw.copy()\n",
    "\n",
    "# First trim stray spaces from column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Rename particularly long or ambiguous headers\n",
    "rename_map = {\n",
    "    'Primary protocol/framework used to compile main inventory': 'Inventory Protocol',\n",
    "    'Gases included in main inventory': 'Included Gases',\n",
    "    'Emissions Question Name': 'Emissions Question',\n",
    "    'Emissions Column Name': 'Emissions Metric',\n",
    "    'Emissions Row Name': 'Emissions Category',\n",
    "    'Emissions Response Answer': 'Emissions Value',\n",
    "    'Emissions Notation Key': 'Emissions Notation',\n",
    "    'Emissions Description': 'Emissions Notes',\n",
    "    'Emissions Data Group': 'Emissions Group',\n",
    "    'Year covered by main inventory': 'Inventory Year',\n",
    "    'Population in year covered by main inventory': 'Inventory Population',\n",
    "    'Boundary of main inventory relative to jurisdiction boundary': 'Inventory Boundary',\n",
    "    'Tool used to compile main inventory': 'Inventory Tool',\n",
    "    'City Location': 'City Location WKT'\n",
    "}\n",
    "df = df.rename(columns=rename_map)\n",
    "\n",
    "# Convert column names to snake_case\n",
    "df.columns = (\n",
    "    df.columns\n",
    "      .str.strip()\n",
    "      .str.lower()\n",
    "      .str.replace(r'[^0-9a-z]+', '_', regex=True)\n",
    "      .str.replace(r'_+', '_', regex=True)\n",
    "      .str.strip('_')\n",
    ")\n",
    "\n",
    "print('Cleaned column names:')\n",
    "df.columns.to_list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea10ac9e",
   "metadata": {},
   "source": [
    "## 4. Data type conversion\n",
    "Convert important fields (year, emissions, population, etc.) to numeric types.\n",
    "Errors are coerced to NaN so unexpected strings become easy to flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d68fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Columns that should be numeric after cleaning\n",
    "numeric_like_cols = [\n",
    "    'inventory_year',\n",
    "    'emissions_value',\n",
    "    'inventory_population',\n",
    "    'organization_number',\n",
    "    'number_of_times_reporting',\n",
    "    'emissions_rank'\n",
    "]\n",
    "\n",
    "for col in numeric_like_cols:\n",
    "    if col in df.columns:\n",
    "        # Remove commas and extra spaces before conversion\n",
    "        df[col] = (\n",
    "            df[col]\n",
    "              .astype(str)\n",
    "              .str.replace(',', '', regex=False)\n",
    "              .str.strip()\n",
    "        )\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "df[numeric_like_cols].dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8ce0b8",
   "metadata": {},
   "source": [
    "## 5. Missing value handling\n",
    "Review null counts, fill the population (single value across rows), and drop records that lack emissions data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f49a71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Review missing values\n",
    "missing_counts = df.isna().sum().sort_values(ascending=False)\n",
    "print('Columns with missing values:')\n",
    "display(missing_counts[missing_counts > 0])\n",
    "\n",
    "# Inventory population is constant for the year; forward fill with that single value\n",
    "if 'inventory_population' in df.columns:\n",
    "    population_values = df['inventory_population'].dropna().unique()\n",
    "    if population_values.size == 1:\n",
    "        df['inventory_population'] = df['inventory_population'].fillna(population_values[0])\n",
    "\n",
    "# Remove rows that do not have an emissions measurement\n",
    "before_drop = df.shape[0]\n",
    "df = df.dropna(subset=['emissions_value'])\n",
    "dropped_rows = before_drop - df.shape[0]\n",
    "print(f'Dropped {dropped_rows} rows lacking emissions values.')\n",
    "\n",
    "df.isna().sum().sort_values(ascending=False).head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe42c77",
   "metadata": {},
   "source": [
    "## 6. Filter to Berlin and select relevant columns\n",
    "Focus on Berlin rows, derive sector and scope, and keep the columns needed for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28ff4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Keep only the City of Berlin\n",
    "df = df[df['city'].str.strip().str.lower() == 'berlin'].copy()\n",
    "print(f'Remaining rows after filtering for Berlin: {df.shape[0]}')\n",
    "\n",
    "# Extract sector information from the hierarchical category\n",
    "if 'emissions_category' in df.columns:\n",
    "    df['sector'] = (\n",
    "        df['emissions_category']\n",
    "          .str.replace('^', '', regex=False)\n",
    "          .str.split('>')\n",
    "          .str[0]\n",
    "          .str.strip()\n",
    "    )\n",
    "    df['category_path'] = df['emissions_category'].str.replace('^', '', regex=False).str.strip()\n",
    "\n",
    "# Map textual descriptions to scope buckets\n",
    "scope_map = {\n",
    "    'direct emissions': 'Scope 1',\n",
    "    'indirect emissions': 'Scope 2',\n",
    "    'outside the jurisdiction boundary': 'Scope 3'\n",
    "}\n",
    "df['scope'] = 'Other/Unknown'\n",
    "for phrase, label in scope_map.items():\n",
    "    df.loc[df['emissions_metric'].str.contains(phrase, case=False, na=False), 'scope'] = label\n",
    "df['scope_category'] = df['scope']\n",
    "\n",
    "# Create harmonised aliases used later in the workflow\n",
    "df['year'] = df['inventory_year'].astype('Int64')\n",
    "df['emissions_tco2e'] = df['emissions_value']\n",
    "df['population'] = df['inventory_population']\n",
    "df['gas_type'] = df.get('included_gases', np.nan)\n",
    "\n",
    "# Keep the most relevant columns for analysis\n",
    "priority_columns = [\n",
    "    'city', 'country', 'year', 'emissions_tco2e', 'sector', 'category_path',\n",
    "    'scope', 'scope_category', 'gas_type', 'population', 'emissions_group',\n",
    "    'emissions_metric', 'emissions_question'\n",
    "]\n",
    "existing_columns = [col for col in priority_columns if col in df.columns]\n",
    "df = df[existing_columns]\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130eb4a2",
   "metadata": {},
   "source": [
    "## 7. Remove duplicate records\n",
    "Drop any duplicated rows to avoid double counting emissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04330eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "before_dedup = df.shape[0]\n",
    "df = df.drop_duplicates()\n",
    "removed = before_dedup - df.shape[0]\n",
    "print(f'Removed {removed} duplicate rows.')\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd9b647",
   "metadata": {},
   "source": [
    "## 8. Feature engineering\n",
    "Create per-capita emissions and tidy the scope category column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1616e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compute per-capita emissions where population data is available\n",
    "if {'emissions_tco2e', 'population'}.issubset(df.columns):\n",
    "    df['emissions_per_capita'] = np.where(\n",
    "        (df['population'] > 0) & ~df['population'].isna(),\n",
    "        df['emissions_tco2e'] / df['population'],\n",
    "        np.nan\n",
    "    )\n",
    "else:\n",
    "    df['emissions_per_capita'] = np.nan\n",
    "\n",
    "# Ensure scope_category is populated (mirrors scope by design)\n",
    "df['scope_category'] = df['scope_category'].fillna(df['scope'])\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9004c382",
   "metadata": {},
   "source": [
    "## 9. Sort, reset index, and export\n",
    "Order the cleaned data, reset the index, and save to a new CSV for downstream analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541d939b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cleaned_path = Path('CSV data') / '2023_City_Wide_Emissions_Berlin_Cleaned.csv'\n",
    "\n",
    "df = df.sort_values(by=['year', 'sector', 'category_path'], ascending=[True, True, True])\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "df.to_csv(cleaned_path, index=False)\n",
    "print(f'Saved cleaned data to: {cleaned_path.resolve()}')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77cf272",
   "metadata": {},
   "source": [
    "## 10. Summary checks\n",
    "Compare shapes before and after cleaning, inspect any remaining nulls, and preview key fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830a23e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    final_shape = df.shape\n",
    "    print(f'Initial shape : {initial_shape}')\n",
    "    print(f'Final shape    : {final_shape}')\n",
    "\n",
    "    print('\n",
    "Missing values after cleaning:')\n",
    "    display(df.isna().sum()[df.isna().sum() > 0])\n",
    "\n",
    "    key_columns = [col for col in ['sector', 'scope_category', 'year'] if col in df.columns]\n",
    "    for col in key_columns:\n",
    "        uniques = df[col].dropna().unique()\n",
    "        print(f\"\n",
    "Unique values for {col!r} ({len(uniques)} found):\")\n",
    "        print(uniques)\n",
    "\n",
    "    df.sample(min(5, len(df)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4aef45",
   "metadata": {},
   "source": [
    "## 11. Quick visualisations\n",
    "Produce a few simple charts to sanity check the cleaned data: totals by sector and scope,\n",
    "plus a trend over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decb6b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure plots render inline when using Jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Bar chart: total emissions per sector\n",
    "if 'sector' in df.columns:\n",
    "    sector_totals = df.groupby('sector')['emissions_tco2e'].sum().sort_values(ascending=False)\n",
    "    sector_totals.plot(kind='bar', ax=axes[0])\n",
    "    axes[0].set_title('Total Emissions by Sector')\n",
    "    axes[0].set_ylabel('tCO2e')\n",
    "else:\n",
    "    axes[0].set_visible(False)\n",
    "\n",
    "# Pie chart: emissions split by scope\n",
    "if 'scope_category' in df.columns:\n",
    "    scope_totals = df.groupby('scope_category')['emissions_tco2e'].sum()\n",
    "    axes[1].pie(scope_totals, labels=scope_totals.index, autopct='%1.1f%%')\n",
    "    axes[1].set_title('Emissions Share by Scope')\n",
    "else:\n",
    "    axes[1].set_visible(False)\n",
    "\n",
    "# Line plot: emissions trend over time\n",
    "if 'year' in df.columns:\n",
    "    yearly_totals = df.groupby('year')['emissions_tco2e'].sum().sort_index()\n",
    "    axes[2].plot(yearly_totals.index, yearly_totals.values, marker='o')\n",
    "    axes[2].set_title('Total Emissions Over Time')\n",
    "    axes[2].set_ylabel('tCO2e')\n",
    "    axes[2].set_xlabel('Year')\n",
    "else:\n",
    "    axes[2].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
